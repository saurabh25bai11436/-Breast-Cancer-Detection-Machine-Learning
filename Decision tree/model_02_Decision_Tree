# Import necessary libraries
import pandas as pd                    # For data manipulation and DataFrame creation
import numpy as np                     # For numerical operations and arrays
from sklearn.datasets import load_breast_cancer  # To load the breast cancer dataset
from sklearn.model_selection import train_test_split  # To split data into train/test sets
from sklearn.tree import DecisionTreeClassifier  # The decision tree algorithm
from sklearn.tree import plot_tree      # To visualize the decision tree
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # Evaluation metrics
import matplotlib.pyplot as plt         # For creating plots and visualizations
import seaborn as sns                   # For enhanced visualizations (nicer looking plots)
import warnings
warnings.filterwarnings('ignore')        # Suppress warning messages


# Load the breast cancer dataset
cancer = load_breast_cancer()           # Loads the Wisconsin Breast Cancer dataset

# Create a DataFrame for better visualization
df = pd.DataFrame(data=cancer.data, columns=cancer.feature_names)  # Convert features to DataFrame
df['target'] = cancer.target             # Add target column (0 or 1)
df['target_name'] = df['target'].map({0: 'malignant', 1: 'benign'})  # Add readable class names

# Display basic information
print("="*60)                            # Print separator line
print("BREAST CANCER DATASET OVERVIEW")
print("="*60)
print("Dataset Shape:", df.shape)        # Shows (569, 32) - 569 samples, 32 columns
print("\nFeatures (30 total):")          # There are 30 medical measurements
print("-" * 30)
for i, feature in enumerate(cancer.feature_names[:10]):  # Show first 10 features
    print(f"{i+1:2d}. {feature}")
print("   ... and 20 more features")

print(f"\nTarget Classes: {cancer.target_names[0]} (0) and {cancer.target_names[1]} (1)")
print("\nClass Distribution:")
print(df['target_name'].value_counts())   # Count of malignant (0) and benign (1)
print(f"\nPercentage Malignant: {(df['target']==0).mean()*100:.1f}%")
print(f"Percentage Benign: {(df['target']==1).mean()*100:.1f}%")

print("\nFirst 5 rows of the dataset:")
print(df.head())                          # Display first 5 rows to see data structure


from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
# Assuming you have your features (X) and target (y) ready
# If not, you'll need to load them (e.g., X = df.drop('target', axis=1))

# 1. DEFINE x_train and y_train (This is the missing piece!)
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 2. Create the Decision Tree model
dt_model = DecisionTreeClassifier(
    max_depth=4,
    min_samples_split=5,
    min_samples_leaf=2,
    max_features='sqrt',
    random_state=42,
    class_weight='balanced'
)

# 3. Train the model
dt_model.fit(x_train, y_train) 

print("Model trained successfully!")


# Make predictions on test data
y_pred = dt_model.predict(X_test)           # Predict classes for test set
y_pred_train = dt_model.predict(X_train)    # Predict classes for training set
y_pred_proba = dt_model.predict_proba(X_test)[:, 1]  # Get probability scores for ROC curve


# 1. Import the necessary function
from sklearn.model_selection import cross_val_score
# Cross-validation score
cv_scores = cross_val_score(dt_model, X_train, y_train, cv=5)  # 5-fold cross-validation
print(f"\nCross-validation scores: {cv_scores}")  # Accuracy for each fold
print(f"Mean CV Score: {cv_scores.mean():.3f} (+/- {cv_scores.std()*2:.3f})")  # Average performance


print("\n" + "="*60)
print("MODEL EVALUATION")
print("="*60)

# Calculate accuracy
train_accuracy = accuracy_score(y_train, y_pred_train)  # Accuracy on training data
test_accuracy = accuracy_score(y_test, y_pred)          # Accuracy on test data

print(f"Training Accuracy: {train_accuracy:.4f}")       # How well model learned training data
print(f"Testing Accuracy: {test_accuracy:.4f}")         # How well model generalizes to new data
print(f"Generalization Gap: {train_accuracy - test_accuracy:.4f}")  # Difference (overfitting indicator)

# Detailed classification report
print("\nClassification Report (Test Set):")
print("-" * 50)
print(classification_report(y_test, y_pred, target_names=cancer.target_names))
# Shows precision, recall, f1-score for each class

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)  # Shows correct and incorrect predictions
print("\nConfusion Matrix:")
print("-" * 30)
print(f"                Predicted")
print(f"                Malignant  Benign")
print(f"Actual Malignant:   {cm[0,0]:3d}       {cm[0,1]:3d}")  # True Negatives, False Positives
print(f"       Benign:      {cm[1,0]:3d}       {cm[1,1]:3d}")  # False Negatives, True Positives



plt.figure(figsize=(8, 6))                    # Create figure of size 8x6 inches
sns.heatmap(cm, 
            annot=True,                        # Show numbers in cells
            fmt='d',                            # Format as integers
            cmap='Blues',                        # Use blue color scheme
            xticklabels=cancer.target_names,     # Label x-axis with class names
            yticklabels=cancer.target_names)     # Label y-axis with class names
plt.title('Confusion Matrix - Breast Cancer Prediction', fontsize=14)
plt.ylabel('Actual', fontsize=12)
plt.xlabel('Predicted', fontsize=12)
plt.tight_layout()                               # Adjust layout to prevent clipping
plt.show()                                        # Display the plot



plt.figure(figsize=(20, 10))                     # Large figure for detailed tree
plot_tree(dt_model, 
          feature_names=cancer.feature_names,     # Label nodes with feature names
          class_names=cancer.target_names,        # Label with class names
          filled=True,                             # Color nodes by majority class
          rounded=True,                            # Rounded corners for nodes
          fontsize=8)                              # Text size
plt.title('Decision Tree for Breast Cancer Prediction', fontsize=16)
plt.show()
